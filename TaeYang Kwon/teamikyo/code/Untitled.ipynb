{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56129c28-5893-410b-94b6-260b61806b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import pickle\n",
    "import random\n",
    "import logging\n",
    "\n",
    "import wandb\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from datasets import load_metric, load_from_disk, load_dataset\n",
    "from transformers import AutoConfig, AutoModelForQuestionAnswering, AutoTokenizer, AdamW\n",
    "from transformers import (\n",
    "    DataCollatorWithPadding,\n",
    "    EvalPrediction,\n",
    "    HfArgumentParser,\n",
    "    TrainingArguments,\n",
    "    set_seed,\n",
    ")\n",
    "\n",
    "from my_model import Mymodel\n",
    "from utils_qa import postprocess_qa_predictions, check_no_error, tokenize, AverageMeter\n",
    "from trainer_qa import QuestionAnsweringTrainer\n",
    "from retrieval import SparseRetrieval\n",
    "from arguments import ModelArguments, DataTrainingArguments\n",
    "from data_processing import DataProcessor\n",
    "from prepare_dataset import make_custom_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ca73587-2eca-4c24-952e-09fc3ac03de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pickle(pickle_path):\n",
    "    '''Custom Dataset을 Load하기 위한 함수'''\n",
    "    f = open(pickle_path, \"rb\")\n",
    "    dataset = pickle.load(f)\n",
    "    f.close()\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b12fcb54-6183-464d-9d11-238be2e564eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = get_pickle(\"/opt/ml/input/data/train_concat5.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8224dec1-aba6-49a7-bc4b-5feba51462ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['answers', 'context', 'id', 'question'],\n",
       "    num_rows: 3952\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_data[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "64eda55f-b335-4ef1-af79-347baff957ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Mecab \n",
    "import re\n",
    "from datasets import Dataset\n",
    "mecab = Mecab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "231c4759-850d-44f1-9e00-05c30d5b2d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_masking(datasets):\n",
    "    context_list = []\n",
    "    question_list = []\n",
    "    id_list = []\n",
    "    answer_list = []\n",
    "    \n",
    "    # train 갯수만큼 iteration\n",
    "    for i in tqdm(range(datasets[\"train\"].num_rows)):\n",
    "        text = datasets[\"train\"][i][\"question\"]\n",
    "        \n",
    "        # 단어 기준 Masking\n",
    "        for word, pos in mecab.pos(text):\n",
    "            first_word = True\n",
    "            # 첫번째 단어는 무조건 Masking(질문 중 가장 중요한 의미를 가지고 있다고 생각)\n",
    "            # 두번째 단어부터는 20% 확률로 Masking\n",
    "            # 하나의 단어만 Masking\n",
    "            if pos in {\"NNG\", \"NNP\"} and (first_word or random.random() > 0.8):\n",
    "                first_word = False\n",
    "                context_list.append(datasets[\"train\"][i][\"context\"])\n",
    "                question_list.append(re.sub(word, \"MASK\", text)) # tokenizer.mask_token\n",
    "                id_list.append(datasets[\"train\"][i][\"id\"])\n",
    "                answer_list.append(datasets[\"train\"][i][\"answers\"])\n",
    "\n",
    "    # list를 Dataset 형태로 변환\n",
    "    datasets[\"train\"] = Dataset.from_dict({\"id\" : id_list,\n",
    "                                           \"context\": context_list, \n",
    "                                           \"question\": question_list,\n",
    "                                           \"answers\": answer_list})\n",
    "\n",
    "    return datasets[\"train\"] # 3000 => 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "34831b52-fafd-48b3-aef1-c6586b58acc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3952/3952 [00:07<00:00, 544.21it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'context', 'question', 'answers'],\n",
       "    num_rows: 20778\n",
       "})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_masking(text_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e21cf6ea-a932-4f80-bd21-d721a31bfc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Mecab, Kkma, Hannanum\n",
    "\n",
    "mecab = Mecab()\n",
    "kkma = Kkma()\n",
    "hannanum = Hannanum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "54867b06-5daa-485e-949e-e15bc99c8d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\"스코틀랜드 계몽주의\", \"언더우드(Underwood)박사와\", \"조선의\", \"나의 노래의\", \"정원 초과와 과적이\", \"내각 회의\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b4485450-b27d-4b46-967f-22132081cee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('스코틀랜드', 'NNP'), ('계몽주의', 'NNG')]\n",
      "[('스코', 'UN'), ('틀', 'NNG'), ('랜드', 'NNG'), ('계몽주의', 'NNG')]\n",
      "[('스코틀랜드', 'N'), ('계몽주의', 'N')]\n",
      "4\n",
      "스코틀랜드 계몽주의\n",
      "[('언더우드', 'NNP'), ('(', 'SSO'), ('Underwood', 'SL'), (')', 'SSC'), ('박사', 'NNG'), ('와', 'JC')]\n",
      "[('언더', 'NNG'), ('우드', 'NNG'), ('(', 'SS'), ('Underwood', 'OL'), (')', 'SS'), ('박사', 'NNG'), ('와', 'JC')]\n",
      "[('언더우드', 'N'), ('(', 'S'), ('Underwood', 'F'), (')', 'S'), ('박사', 'N'), ('와', 'J')]\n",
      "언더우드(Underwood)박사\n",
      "[('조선', 'NNP'), ('의', 'JKB')]\n",
      "[('조선', 'NNG'), ('의', 'JKG')]\n",
      "[('조선', 'N'), ('의', 'J')]\n",
      "1\n",
      "조선\n",
      "[('나', 'NP'), ('의', 'JKG'), ('노래', 'NNG'), ('의', 'NNG')]\n",
      "[('나의', 'NNG'), ('노래', 'NNG'), ('의', 'JKG')]\n",
      "[('나', 'N'), ('의', 'J'), ('노래', 'N'), ('의', 'J')]\n",
      "1\n",
      "나의 노래\n",
      "[('정원', 'NNG'), ('초과', 'NNG'), ('와', 'JC'), ('과', 'NNG'), ('적', 'XSN'), ('이', 'VCP')]\n",
      "[('정원', 'NNG'), ('초과', 'NNG'), ('와', 'JKM'), ('과적', 'NNG'), ('이', 'JKS')]\n",
      "[('정원', 'N'), ('초과', 'N'), ('와', 'J'), ('과', 'N'), ('적', 'X'), ('이', 'J')]\n",
      "정원 초과와 과적\n",
      "[('내각', 'NNP'), ('회의', 'NNG')]\n",
      "[('내각', 'NNG'), ('회의', 'NNG')]\n",
      "[('내각', 'N'), ('회의', 'N')]\n",
      "2\n",
      "내각 회의\n"
     ]
    }
   ],
   "source": [
    "for text in texts:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e3243a-f6a0-42c2-bc31-539d77e8f8f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2b4ffa-569a-4555-992d-298e5f06b3e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c592a22-63dd-4ff8-8dcb-add650732c99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c3f965-c0a2-4043-ad07-5dab1c6d7c25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a094b6-e954-44ec-9933-c42d52bcca19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256827e3-9b18-4e94-b80a-b603ce0b320c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
